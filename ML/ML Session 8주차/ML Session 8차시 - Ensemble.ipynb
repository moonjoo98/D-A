{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Data Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "seed = 42\n",
    "skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=seed)\n",
    "\n",
    "# Modeling\n",
    "from sklearn.model_selection import cross_val_score\n",
    "#  - Bagging,models\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "#  - Boosting models\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# Ensemble\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "# Evaluation\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(184172, 75) (78932, 75) (184172,)\n"
     ]
    }
   ],
   "source": [
    "train_features = pd.read_csv('./data/train_features.csv')\n",
    "test_features = pd.read_csv('./data/test_features.csv')\n",
    "target = pd.read_csv('./data/target.csv').LABEL\n",
    "print(train_features.shape, test_features.shape, target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Hold Out Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128920, 75) (55252, 75) (128920,) (55252,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(train_features, target, test_size = 0.3, random_state = seed)\n",
    "print(X_train.shape, X_valid.shape, y_train.shape, y_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ExtraTreesClassifier', ExtraTreesClassifier(n_jobs=-1, random_state=42)),\n",
       " ('XGBClassifier',\n",
       "  XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
       "                colsample_bynode=None, colsample_bytree=None, gamma=None,\n",
       "                gpu_id=None, importance_type='gain', interaction_constraints=None,\n",
       "                learning_rate=None, max_delta_step=None, max_depth=None,\n",
       "                min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "                n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n",
       "                random_state=42, reg_alpha=None, reg_lambda=None,\n",
       "                scale_pos_weight=None, subsample=None, tree_method=None,\n",
       "                validate_parameters=False, verbosity=None)),\n",
       " ('LGBMClassifier', LGBMClassifier(random_state=42))]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_clf = RandomForestClassifier(random_state=seed, n_jobs=-1)\n",
    "extra_clf = ExtraTreesClassifier(random_state=seed, n_jobs=-1)\n",
    "gbm_clf = GradientBoostingClassifier(random_state=seed)\n",
    "xgb_clf = XGBClassifier(random_state=seed, n_jobs=-1)\n",
    "lgb_clf = LGBMClassifier(random_state=seed, n_jobs=-1)\n",
    "\n",
    "models = [extra_clf, xgb_clf, lgb_clf]\n",
    "\n",
    "estimators = [(model.__class__.__name__, model) for model in models]\n",
    "estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.Voting - soft voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4054019107242492\n"
     ]
    }
   ],
   "source": [
    "# voting 파라미터로 hard/soft 선택\n",
    "# hard -> 최빈값, soft -> 평균\n",
    "\n",
    "voting_clf = VotingClassifier(estimators = estimators, voting='soft', n_jobs=-1)\n",
    "voting_clf.fit(X_train, y_train)\n",
    "pred = voting_clf.predict_proba(X_valid)\n",
    "test_score = log_loss(y_valid, pred)\n",
    "print(test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**성능을 내기 위해 위에 Voting에 추가적으로 해볼 수 있다고 생각되는 것들**\n",
    " - voting에 들어가는 모델들이 알고리즘적으로 다른 계열의 모델들을 사용함(logistic regression, knn, mlp, svc 등등)\n",
    " - 모델들을 더 많이 넣어 voting한다고 해서 성능이 개선되지는 않음, 성능이 좋으면서 서로 보완할 수 있을 것 같은 모델들을 앙상블 해야함\n",
    " - voting에 들어가는 모델들을 튜닝하여 좋은 성능이 나오는 모델을 voting에 사용함\n",
    " - voting_clf로 fit(학습)을 시킬 때 cross_validation방법을 사용함\n",
    " \n",
    " \n",
    "모든 방법론에 있어서 이렇게 하는게 좋다 저렇게 하는게 좋다 같은 정답은 없음  \n",
    "결국 다양한 시도를 통해 성능을 통해 감을 잡고 적당한 방법론을 택해야 함  \n",
    "또한 꼭 앙상블한다고 해서 성능이 오르는 것은 아님, 오히려 싱글모델이 나을 때도 있음  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - 스태킹은 sklearn, mlxtend, vecstack 등 다양한 패키지에서 제공함.  \n",
    "다들 사용법이 비슷하며 해당 코드에서는 이해하기 쉬운 sklearn의 패키지를 사용하기로 함.  \n",
    "참고로 조윤호 교수님은 vecstack을 이용함. 패키지마다의 속도 차이도 존재.  \n",
    " - voting보다 stacking이 더 오래 걸림(현 스크립트 기준)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ?을 통해서 패키지 내부의 파라미터 인자 확인 가능\n",
    "# ex) StackingClassifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [('rf', rf_clf), ('xgb', xgb_clf)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3992179201696497\n"
     ]
    }
   ],
   "source": [
    "stk_clf = StackingClassifier(estimators = estimators,\n",
    "                            final_estimator = lgb_clf, cv=skf, n_jobs=-1)\n",
    "\n",
    "stk_clf.fit(X_train, y_train)\n",
    "pred = stk_clf.predict_proba(X_valid)\n",
    "test_score = log_loss(y_valid, pred)\n",
    "print(test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**성능을 내기 위해 위에 Stacking에 추가적으로 해볼 수 있다고 생각되는 것들**\n",
    " - 위에 voting 성능을 위해 적어 놓은 것들\n",
    " - meta 모델에는 사용했던 모델을 또 넣어도 되고 다른 모델을 넣어도 됨. 정답은 없음\n",
    " - vecstack를 이용하면 meta_clf를 stk_clf 내부에서 설정하지 않고 따로 외부에서 정의함. 이때 meta_clf를 튜닝하여 사용할 수 있겠음. (메타 모델 튜닝의 방법론)\n",
    " - meta 모델에 대한 cross_validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 Layer Stacking\n",
    " - 이중 스태킹 : meta 모델에 단일 모델이 아닌 앙상블 모델을 넣어 두번 앙상블한다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "     - 스태킹을 두번 하는 경우 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 먼저 두번째에 들어갈 스태킹 층을 만들어줌, 최종적으로 메타모델이 될 모델은 gbm_clf\n",
    "stk_layer2 = StackingClassifier(estimators = [('extra', extra_clf), ('lgb', lgb_clf)],\n",
    "                            final_estimator = gbm_clf, cv=skf, n_jobs=-1)\n",
    "\n",
    "# 메타 모델에 앞서 만든 두번 째 층 스태킹을 넣어줌\n",
    "stk_clf = StackingClassifier(estimators = [('rf', rf_clf), ('xgb', xgb_clf)],\n",
    "                            final_estimator = stk_layer2, cv=skf, n_jobs=-1)\n",
    "\n",
    "\n",
    "stk_clf.fit(X_train, y_train)\n",
    "pred = stk_clf.predict_proba(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39809573171689083\n"
     ]
    }
   ],
   "source": [
    "test_score = log_loss(y_valid, pred)\n",
    "print(test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "     - 스태킹 후 보팅을 하는 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41912649143108893\n"
     ]
    }
   ],
   "source": [
    "voting_layer2 = VotingClassifier(estimators = [('extra', extra_clf), ('lgb', lgb_clf)], voting='soft', n_jobs=-1)\n",
    "    # 앞에서 훈련한 보팅 모델을 가져다 쓰는 방법도 있음\n",
    "\n",
    "stk_clf = StackingClassifier(estimators = [('rf', rf_clf), ('xgb', xgb_clf)],\n",
    "                            final_estimator = voting_layer2, cv=skf, n_jobs=-1)\n",
    "\n",
    "stk_clf.fit(X_train, y_train)\n",
    "pred = stk_clf.predict_proba(X_valid)\n",
    "test_score = log_loss(y_valid, pred)\n",
    "print(test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission Ensemble\n",
    " - 아래 코드는 예시임\n",
    " - 해당 서브미션 앙상블 또한 정답은 없으며 여러 시도를 거쳐서 어떤 방법이 성능이 잘 나오는지 테스크마다 확인해야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.970217\n",
       "1    0.709358\n",
       "2    0.318606\n",
       "3    0.543408\n",
       "4    0.945127\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    0.891055\n",
       "1    0.245481\n",
       "2    0.672198\n",
       "3    0.807093\n",
       "4    0.675388\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    0.671197\n",
       "1    0.489294\n",
       "2    0.555514\n",
       "3    0.708393\n",
       "4    0.293071\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sub_1 = pd.Series(np.random.ranf(5))\n",
    "sub_2 = pd.Series(np.random.ranf(5))\n",
    "sub_3 = pd.Series(np.random.ranf(5))\n",
    "\n",
    "subs = [sub_1, sub_2, sub_3]\n",
    "\n",
    "# 3개의 서브미션이 아래와 같이 찍혔다고 가정\n",
    "# 전제 조건1 : 3개의 서브미션이 비슷한 방법이 아닌 각자 다른 방법으로 찍힘\n",
    "# 전제 조건2 : 3개의 서브미션의 성능이 서로 비슷함\n",
    "display(sub_1)\n",
    "display(sub_2)\n",
    "display(sub_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.844157\n",
       "1    0.481378\n",
       "2    0.515439\n",
       "3    0.686298\n",
       "4    0.637862\n",
       "dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 산술평균\n",
    "final_sub = sum(subs) / len(subs)\n",
    "final_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.83408046, 0.44003197, 0.4918306 , 0.67728997, 0.57192467])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 기하평균\n",
    "from scipy.stats.mstats import gmean\n",
    "final_sub = gmean(subs)\n",
    "final_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.875672\n",
       "1    0.538373\n",
       "2    0.466231\n",
       "3    0.650576\n",
       "4    0.714678\n",
       "dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 가중평균\n",
    "final_sub = (sub_1 * 0.5) + (sub_2 * 0.25) + (sub_3 * 0.25)\n",
    "final_sub\n",
    "\n",
    "# 그 외 조화평균, 멱평균 등의 방법들도 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **────────────────────────End of Pipeline──────────────────────**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
