{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f85b298",
   "metadata": {},
   "source": [
    "## LeNet Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae959a9",
   "metadata": {},
   "source": [
    "<img src='http://drive.google.com/uc?export=view&id=1MevERvWOuYttJyTaFbGDJggB3luPD0TP' /><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7febc0ff",
   "metadata": {},
   "source": [
    "LeNet-5는 32x32 크기의 흑백 이미지에서 학습된 7 layer Convolutional Neural Network  \n",
    "\n",
    "[Conv(C1) - Subsampling(S2) - Conv(C3) - Subsampling(S4) - Conv(C5) - FC - FC]  \n",
    "\n",
    "**Input**  \n",
    "입력 이미지는 32x32  \n",
    "**Layer C1**  \n",
    "5x5 크기의 kernel 6개와 stride=1, convolutional layer  \n",
    "입력 크기는 32x32x1 이고, 출력 크기는 28x28x6  \n",
    "**Layer S2**   \n",
    "2x2 크기의 kernel 6개와 stride=2, subsampling layer  \n",
    "입력 크기는 28x28x6 이고, 출력 크기는 14x14x6  \n",
    "**Layer C3**  \n",
    "5x5 크기의 kernel 16개와 stride=1, convolution layer  \n",
    "입력 크기는 14x14x6 이고, 출력 크기는 10x10x16  \n",
    "**Layer S4**  \n",
    "2x2 크기의 kernel 16개와 stride=2, subsampling layer  \n",
    "입력 크기는 10x10x16 이고, 출력 크기는 5x5x16  \n",
    "**Layer C5**  \n",
    "5x5 크기의 kernel 120개와 stride=1, convolutional layer  \n",
    "입력 크기는 5x5x16 이고, 출력 크기는 1x1x120  \n",
    "**Layer F6**  \n",
    "tanh 함수를 활성화 함수로 이용하는 fully-connected layer  \n",
    "입력 유닛은 120개 이고, 출력 유닛은 84개  \n",
    "**Layer F7**  \n",
    "RBF(Euclidean Radia Basis Function unit)를 활성화 함수로 이용하는 output layer  \n",
    "입력 크기는 84 이고, 출력 크기는 10  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444996ca",
   "metadata": {},
   "source": [
    "(1) 필요한 라이브러리 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7aef9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu' "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c4d89b",
   "metadata": {},
   "source": [
    "(2) Parameters 설정하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf391bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "RANDOM_SEED = 42\n",
    "LEARNING_RATE = 0.001\n",
    "BATCH_SIZE = 32\n",
    "N_EPOCHS = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7c4ccf",
   "metadata": {},
   "source": [
    "(3) 정확도를 구하는 function과 손실을 시각화 하는 function 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fab7f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(model, data_loader, device):\n",
    "    '''\n",
    "    전체 data_loader에 대한 예측의 정확도를 계산하는 함수\n",
    "    '''\n",
    "    \n",
    "    correct_pred = 0 \n",
    "    n = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for X, y_true in data_loader:\n",
    "\n",
    "            X = X.to(device)\n",
    "            y_true = y_true.to(device)\n",
    "\n",
    "            _, y_prob = model(X)\n",
    "            _, predicted_labels = torch.max(y_prob, 1)\n",
    "\n",
    "            n += y_true.size(0)\n",
    "            correct_pred += (predicted_labels == y_true).sum()\n",
    "\n",
    "    return correct_pred.float() / n\n",
    "\n",
    "def plot_losses(train_losses, valid_losses):\n",
    "    '''\n",
    "    training과 validation loss를 시각화하는 함수\n",
    "    '''\n",
    "    \n",
    "    # plot style을 seaborn으로 설정\n",
    "    plt.style.use('seaborn')\n",
    "\n",
    "    train_losses = np.array(train_losses) \n",
    "    valid_losses = np.array(valid_losses)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize = (8, 4.5))\n",
    "\n",
    "    ax.plot(train_losses, color='blue', label='Training loss') \n",
    "    ax.plot(valid_losses, color='red', label='Validation loss')\n",
    "    ax.set(title=\"Loss over epochs\", \n",
    "            xlabel='Epoch',\n",
    "            ylabel='Loss') \n",
    "    ax.legend()\n",
    "    fig.show()\n",
    "    \n",
    "    # plot style을 기본값으로 설정\n",
    "    plt.style.use('default')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec55ba50",
   "metadata": {},
   "source": [
    "(4) training data에 사용되는 helper 함수 정의하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acde3c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, device):\n",
    "    '''\n",
    "    training loop의 training 단계에 대한 함수\n",
    "    '''\n",
    "\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    \n",
    "    for X, y_true in train_loader:\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        X = X.to(device)\n",
    "        y_true = y_true.to(device)\n",
    "    \n",
    "        # 순전파\n",
    "        y_hat, _ = model(X) \n",
    "        loss = criterion(y_hat, y_true) \n",
    "        running_loss += loss.item() * X.size(0)\n",
    "\n",
    "        # 역전파\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    return model, optimizer, epoch_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a26c18",
   "metadata": {},
   "source": [
    "(5) validation data에 사용되는 함수 정의하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84ba0e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#validation 단계에서는 역전파를 진행하지 않습니다.\n",
    "\n",
    "def validate(valid_loader, model, criterion, device):\n",
    "    '''\n",
    "    training loop의 validation 단계에 대한 함수\n",
    "    '''\n",
    "   \n",
    "    model.eval()\n",
    "    running_loss = 0\n",
    "    \n",
    "    for X, y_true in valid_loader:\n",
    "    \n",
    "        X = X.to(device)\n",
    "        y_true = y_true.to(device)\n",
    "\n",
    "        # 순전파와 손실 기록하기\n",
    "        y_hat, _ = model(X) \n",
    "        loss = criterion(y_hat, y_true) \n",
    "        running_loss += loss.item() * X.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(valid_loader.dataset)\n",
    "        \n",
    "    return model, epoch_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139e03a4",
   "metadata": {},
   "source": [
    "(6) training loop 정의하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7df8ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(model, criterion, optimizer, train_loader, valid_loader, epochs, device, print_every=1):\n",
    "    '''\n",
    "    전체 training loop를 정의하는 함수\n",
    "    '''\n",
    "    \n",
    "    # metrics를 저장하기 위한 객체 설정\n",
    "    best_loss = 1e10\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    " \n",
    "    # model 학습하기\n",
    "    for epoch in range(0, epochs):\n",
    "\n",
    "        # training\n",
    "        model, optimizer, train_loss = train(train_loader, model, criterion, optimizer, device)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        # validation\n",
    "        with torch.no_grad():\n",
    "            model, valid_loss = validate(valid_loader, model, criterion, device)\n",
    "            valid_losses.append(valid_loss)\n",
    "\n",
    "        if epoch % print_every == (print_every - 1):\n",
    "            \n",
    "            train_acc = get_accuracy(model, train_loader, device=device)\n",
    "            valid_acc = get_accuracy(model, valid_loader, device=device)\n",
    "                \n",
    "            print(f'{datetime.now().time().replace(microsecond=0)} --- '\n",
    "                  f'Epoch: {epoch}\\t'\n",
    "                  f'Train loss: {train_loss:.4f}\\t'\n",
    "                  f'Valid loss: {valid_loss:.4f}\\t'\n",
    "                  f'Train accuracy: {100 * train_acc:.2f}\\t'\n",
    "                  f'Valid accuracy: {100 * valid_acc:.2f}')\n",
    "\n",
    "    plot_losses(train_losses, valid_losses)\n",
    "    \n",
    "    return model, optimizer, (train_losses, valid_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a1ed97",
   "metadata": {},
   "source": [
    "(7) data 준비하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72acd08a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rudtj\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "#data는 torchvision에서 제공하는 MNIST data를 사용합니다.\n",
    "\n",
    "# transforms 정의하기\n",
    "transforms = transforms.Compose([transforms.Resize((32, 32)),\n",
    "                                 transforms.ToTensor()])\n",
    "\n",
    "# data set 다운받고 생성하기\n",
    "train_dataset = datasets.MNIST(root='mnist_data', \n",
    "                               train=True, \n",
    "                               transform=transforms,\n",
    "                               download=True)\n",
    "\n",
    "valid_dataset = datasets.MNIST(root='mnist_data', \n",
    "                               train=False, \n",
    "                               transform=transforms)\n",
    "\n",
    "# data loader 정의하기\n",
    "train_loader = DataLoader(dataset=train_dataset, \n",
    "                          batch_size=BATCH_SIZE, \n",
    "                          shuffle=True)\n",
    "\n",
    "valid_loader = DataLoader(dataset=valid_dataset, \n",
    "                          batch_size=BATCH_SIZE, \n",
    "                          shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1ce730",
   "metadata": {},
   "source": [
    "(8) 불러온 MNIST data 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4c1de7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: torch.Size([32, 1, 32, 32]) type: torch.FloatTensor\n",
      "y_train: torch.Size([32]) type: torch.LongTensor\n"
     ]
    }
   ],
   "source": [
    "for (X_train, y_train) in train_loader:\n",
    "    print('X_train:', X_train.size(), 'type:', X_train.type())\n",
    "    print('y_train:', y_train.size(), 'type:', y_train.type())\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690b1e48",
   "metadata": {},
   "source": [
    "(9) LeNet-5 구조 정의하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f00d5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No.1\n",
    "\n",
    "class LeNet5(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(LeNet5, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(in_channels=16, out_channels=120, kernel_size=5, stride=1)\n",
    "        \n",
    "        \n",
    "        self.pool = nn.AvgPool2d(kernel_size=2)\n",
    "        \n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=120, out_features=84)\n",
    "        self.fc2 = nn.Linear(in_features=84, out_features=10)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.tanh(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.tanh(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.conv3(x)\n",
    "        x = F.tanh(x)\n",
    "        \n",
    "        x = torch.flatten(x, 1)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = F.tanh(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        probs = F.softmax(x, dim=1)\n",
    "        return x, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c2d3f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No.2\n",
    "\n",
    "class LeNet5_Sequential(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(LeNet5_Sequential, self).__init__()\n",
    "        \n",
    "        self.feature_extractor = nn.Sequential( \n",
    "            \n",
    "            nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1),\n",
    "            nn.Tanh(),\n",
    "            nn.AvgPool2d(kernel_size=2),\n",
    "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1),\n",
    "            nn.Tanh(),\n",
    "            nn.AvgPool2d(kernel_size=2),\n",
    "            nn.Conv2d(in_channels=16, out_channels=120, kernel_size=5, stride=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(in_features=120, out_features=84),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(in_features=84, out_features=10),\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        probs = F.softmax(x, dim=1)\n",
    "        return x, probs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a784df",
   "metadata": {},
   "source": [
    "(10) model, optimizer, loss function 설정하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a045450",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "model = LeNet5().to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2cb3de",
   "metadata": {},
   "source": [
    "(11) 신경망 학습하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e11545b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rudtj\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23:22:42 --- Epoch: 0\tTrain loss: 0.2290\tValid loss: 0.1021\tTrain accuracy: 96.85\tValid accuracy: 96.80\n",
      "23:23:01 --- Epoch: 1\tTrain loss: 0.0762\tValid loss: 0.0621\tTrain accuracy: 98.38\tValid accuracy: 98.20\n",
      "23:23:19 --- Epoch: 2\tTrain loss: 0.0550\tValid loss: 0.0519\tTrain accuracy: 98.69\tValid accuracy: 98.50\n",
      "23:23:39 --- Epoch: 3\tTrain loss: 0.0431\tValid loss: 0.0475\tTrain accuracy: 99.11\tValid accuracy: 98.53\n",
      "23:23:59 --- Epoch: 4\tTrain loss: 0.0353\tValid loss: 0.0455\tTrain accuracy: 99.30\tValid accuracy: 98.71\n",
      "23:24:19 --- Epoch: 5\tTrain loss: 0.0287\tValid loss: 0.0414\tTrain accuracy: 99.38\tValid accuracy: 98.72\n",
      "23:24:40 --- Epoch: 6\tTrain loss: 0.0253\tValid loss: 0.0438\tTrain accuracy: 99.49\tValid accuracy: 98.56\n",
      "23:25:00 --- Epoch: 7\tTrain loss: 0.0223\tValid loss: 0.0477\tTrain accuracy: 99.54\tValid accuracy: 98.52\n",
      "23:25:19 --- Epoch: 8\tTrain loss: 0.0185\tValid loss: 0.0441\tTrain accuracy: 99.55\tValid accuracy: 98.70\n",
      "23:25:38 --- Epoch: 9\tTrain loss: 0.0173\tValid loss: 0.0493\tTrain accuracy: 99.53\tValid accuracy: 98.55\n",
      "23:25:58 --- Epoch: 10\tTrain loss: 0.0156\tValid loss: 0.0533\tTrain accuracy: 99.57\tValid accuracy: 98.50\n",
      "23:26:18 --- Epoch: 11\tTrain loss: 0.0150\tValid loss: 0.0473\tTrain accuracy: 99.67\tValid accuracy: 98.69\n",
      "23:26:38 --- Epoch: 12\tTrain loss: 0.0125\tValid loss: 0.0387\tTrain accuracy: 99.76\tValid accuracy: 98.94\n",
      "23:26:59 --- Epoch: 13\tTrain loss: 0.0118\tValid loss: 0.0444\tTrain accuracy: 99.67\tValid accuracy: 98.69\n",
      "23:27:19 --- Epoch: 14\tTrain loss: 0.0117\tValid loss: 0.0517\tTrain accuracy: 99.68\tValid accuracy: 98.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-eb39e4490d4d>:43: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  fig.show()\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x324 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model, optimizer, _ = training_loop(model, criterion, optimizer, train_loader, \n",
    "                                    valid_loader, N_EPOCHS, DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1f2e91",
   "metadata": {},
   "source": [
    "## Alexnet Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2dfa75",
   "metadata": {},
   "source": [
    "<img src='https://t1.daumcdn.net/cfile/tistory/99FEB93C5C80B5192E' /><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75f113e",
   "metadata": {},
   "source": [
    "Alexnet은 3x227x227 크기의 이미지에서 학습되었으며, 2개의 GPU로 병렬연산을 수행한 8 layer Convolutional Neural Network이다.   \n",
    "\n",
    "[Input – Conv1 – MaxPool1 – Norm1 – Conv2 – MaxPool2 – Norm2 – Conv3 – Conv4 – Conv5 – MaxPool5 – FC6- FC7- FC8(output)]  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be94342d",
   "metadata": {},
   "source": [
    "Alexnet 구조 정의하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d80b9380",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "    def __init__(self, num_classes: int = 1000, init_weights: bool = True):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.fstblock_1 = nn.Sequential(\n",
    "            # Input Channel (RGB: 3)\n",
    "            nn.Conv2d(in_channels=3, out_channels=48, kernel_size=11, padding=0, stride=4),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2), \n",
    "            nn.LocalResponseNorm(size=5, k=2),\n",
    "            nn.Conv2d(in_channels=48, out_channels=128, kernel_size=5, padding=2, stride=1), \n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2), \n",
    "            nn.LocalResponseNorm(size=5, k=2),\n",
    "        )\n",
    "        self.fstblock_2 = nn.Sequential(\n",
    "            # Input Channel (RGB: 3)\n",
    "            nn.Conv2d(in_channels=3, out_channels=48, kernel_size=11, padding=0, stride=4), \n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2), \n",
    "            nn.LocalResponseNorm(size=5, k=2),\n",
    "            nn.Conv2d(in_channels=48, out_channels=128, kernel_size=5, padding=2, stride=1), \n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2), \n",
    "            nn.LocalResponseNorm(size=5, k=2),\n",
    "        )\n",
    "\n",
    "        self.cross_conv_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=128, out_channels=96, kernel_size=3, padding=1, stride=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.cross_conv_2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=128, out_channels=96, kernel_size=3, padding=1, stride=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        self.sndblock_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=192, out_channels=192, kernel_size=3, padding=1, stride=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=192, out_channels=128, kernel_size=3, padding=1, stride=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2), \n",
    "        )\n",
    "        self.sndblock_2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=192, out_channels=192, kernel_size=3, padding=1, stride=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=192, out_channels=128, kernel_size=3, padding=1, stride=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2), \n",
    "        )\n",
    "\n",
    "        self.crossfc1_1 = nn.Sequential(\n",
    "            nn.Linear(128 * 6 * 6, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5)\n",
    "        )\n",
    "        self.crossfc1_2 = nn.Sequential(\n",
    "            nn.Linear(128 * 6 * 6, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5)\n",
    "        )\n",
    "\n",
    "        self.crossfc2_1 = nn.Sequential(\n",
    "            nn.Linear(2048, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5)\n",
    "        )\n",
    "        self.crossfc2_2 = nn.Sequential(\n",
    "            nn.Linear(2048, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5)\n",
    "        )\n",
    "\n",
    "        self.classifier_1 = nn.Linear(2048, num_classes)\n",
    "        self.classifier_2 = nn.Linear(2048, num_classes)\n",
    "    \n",
    "    def forward(self, x:torch.Tensor):\n",
    "        # First Block\n",
    "        x1 = self.fstblock_1(x)\n",
    "        x2 = self.fstblock_2(x)\n",
    "\n",
    "        # Cross\n",
    "        x3 = self.cross_conv_1(x1) # Left Block 1\n",
    "        x4 = self.cross_conv_2(x2) # Left Block 2\n",
    "\n",
    "        x5 = self.cross_conv_1(x1) # Right Block 1\n",
    "        x6 = self.cross_conv_2(x2) # Right Block 2\n",
    "\n",
    "        x1 = torch.cat([x3, x4], 1)\n",
    "        x2 = torch.cat([x5, x6], 1)\n",
    "\n",
    "        # Second Block\n",
    "        x1 = self.sndblock_1(x1)\n",
    "        x2 = self.sndblock_2(x2)\n",
    "\n",
    "        x1 = torch.flatten(x1, 1)\n",
    "        x2 = torch.flatten(x2, 1)\n",
    "\n",
    "        # FC Layer (Cross)\n",
    "        x3 = crossfc1_1(x1) # Left FC 1\n",
    "        x4 = crossfc1_2(x2) # Left FC 2\n",
    "\n",
    "        x5 = crossfc1_1(x1) # Right FC 1\n",
    "        x6 = crossfc1_2(x2) # Right FC 2\n",
    "\n",
    "        x1 = torch.cat([x3, x4], 1)\n",
    "        x2 = torch.cat([x5, x6], 1)\n",
    "\n",
    "        # FC Layer (Cross)\n",
    "        x3 = crossfc2_1(x1) # Left FC 1\n",
    "        x4 = crossfc2_2(x2) # Left FC 2\n",
    "\n",
    "        x5 = crossfc2_1(x1) # Right FC 1\n",
    "        x6 = crossfc2_2(x2) # Right FC 2\n",
    "\n",
    "        x1 = torch.cat([x3, x4], 1)\n",
    "        x2 = torch.cat([x5, x6], 1)\n",
    "\n",
    "        x1 = classifier_1(x1)\n",
    "        x2 = classifier_2(x2)\n",
    "\n",
    "        x = (x1 + x2)/2\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418b1c20",
   "metadata": {},
   "source": [
    "## VGG16 Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7394b29",
   "metadata": {},
   "source": [
    "<img src='https://blog.kakaocdn.net/dn/K990l/btqwDJ7C54R/664Ksm6gyTGBR1wK3YPDFk/img.png' /><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482531e2",
   "metadata": {},
   "source": [
    "VGG16은 3x224x224 크기의 이미지에서 학습된 16 layer Convolutional Neural Network이다.   \n",
    "\n",
    "[Input – C1 – C2 – MaxPool2 – C3 – C4 – MaxPool4 – C5 – C6 – C7 – MaxPool7 – C8 – C9 – C10 – MaxPool10 – C11 – C12 – C13 – MaxPool13 – FC14 – FC15 – FC16(Output)]     \n",
    "\n",
    "**Input**  \n",
    "입력 이미지 3x224x224  \n",
    "    \n",
    "**Layer C1**  \n",
    "3x3 크기의 kernel 64개, stride=1, padding=1인 convolutional layer  \n",
    "입력 크기는 3x224x224 이고, 출력 크기는 64x224x224  \n",
    "**Layer C2**\n",
    "3x3 크기의 kernel 64개, stride=1, padding=1인 convolutional layer  \n",
    "입력 크기는 64x224x224 이고, 출력 크기는 64x224x224  \n",
    "**Layer Maxpool2**  \n",
    "2x2 크기의 kernel, stride=2인 maxpooling layer  \n",
    "입력 크기는 64x224x224 이고, 출력 크기는 64x112x112  \n",
    "    \n",
    "**Layer C3**  \n",
    "3x3 크기의 kernel 128개, stride=1, padding=1인 convolutional layer  \n",
    "입력 크기는 64x112x112 이고, 출력 크기는 128x112x112  \n",
    "**Layer C4**  \n",
    "3x3 크기의 kernel 128개, stride=1, padding=1인 convolutional layer  \n",
    "입력 크기는 128x112x112 이고, 출력 크기는 128x112x112  \n",
    "**Layer Maxpool4**  \n",
    "2x2 크기의 kernel, stride=2인 maxpooling layer  \n",
    "입력 크기는 128x112x112 이고, 출력 크기는 128x56x56  \n",
    "    \n",
    "**Layer C5**  \n",
    "3x3 크기의 kernel 256개, stride=1, padding=1인 convolutional layer  \n",
    "입력 크기는 128x56x56 이고, 출력 크기는 256x56x56  \n",
    "**Layer C6**  \n",
    "3x3 크기의 kernel 256개, stride=1, padding=1인 convolutional layer  \n",
    "입력 크기는 256x56x56 이고, 출력 크기는 256x56x56  \n",
    "**Layer C7**  \n",
    "3x3 크기의 kernel 256개, stride=1, padding=1인 convolutional layer  \n",
    "입력 크기는 256x56x56 이고, 출력 크기는 256x56x56  \n",
    "**Layer Maxpool7**  \n",
    "2x2 크기의 kernel, stride=2인 maxpooling layer  \n",
    "입력 크기는 256x56x56 이고, 출력 크기는 256x28x28  \n",
    "    \n",
    "**Layer C8**  \n",
    "3x3 크기의 kernel 512개, stride=1, padding=1인 convolutional layer  \n",
    "입력 크기는 256x28x28 이고, 출력 크기는 512x28x28  \n",
    "**Layer C9**  \n",
    "3x3 크기의 kernel 512개, stride=1, padding=1인 convolutional layer  \n",
    "입력 크기는 512x28x28 이고, 출력 크기는 512x28x28  \n",
    "**Layer C10**  \n",
    "3x3 크기의 kernel 512개, stride=1, padding=1인 convolutional layer  \n",
    "입력 크기는 512x28x28 이고, 출력 크기는 512x28x28  \n",
    "**Layer Maxpool10**  \n",
    "2x2 크기의 kernel, stride=2인 maxpooling layer  \n",
    "입력 크기는 512x28x28 이고, 출력 크기는 512x14x14  \n",
    "    \n",
    "**Layer C11**  \n",
    "3x3 크기의 kernel 512개, stride=1, padding=1인 convolutional layer  \n",
    "입력 크기는 512x14x14 이고, 출력 크기는 512x14x14  \n",
    "**Layer C12**  \n",
    "3x3 크기의 kernel 512개, stride=1, padding=1인 convolutional layer  \n",
    "입력 크기는 512x14x14 이고, 출력 크기는 512x14x14  \n",
    "**Layer C13**  \n",
    "3x3 크기의 kernel 512개, stride=1, padding=1인 convolutional layer  \n",
    "입력 크기는 512x14x14 이고, 출력 크기는 512x14x14  \n",
    "**Layer Maxpool13**  \n",
    "2x2 크기의 kernel, stride=2인 maxpooling layer  \n",
    "입력 크기는 512x14x14 이고, 출력 크기는 512x7x7  \n",
    "    \n",
    "**Layer F14**  \n",
    "ReLU를 활성화 함수로 이용하는 fully connected layer  \n",
    "입력 크기는 25088 이고, 출력 크기는 4096  \n",
    "**Layer F15**  \n",
    "ReLU를 활성화 함수로 이용하는 fully connected layer  \n",
    "입력 크기는 4096 이고, 출력 크기는 4096  \n",
    "**Layer F16**  \n",
    "ReLU를 활성화 함수로 이용하는 output layer  \n",
    "입력 크기는 4096 이고, 출력 크기는 1000  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19066d90",
   "metadata": {},
   "source": [
    "VGG16 구조 정의하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed12e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG_A(nn.Module):\n",
    "    def __init__(self, num_classes: int = 1000, init_weights: bool = True):\n",
    "        super(VGG_A, self).__init__()\n",
    "        self.convnet = nn.Sequential(\n",
    "            # Input Channel (RGB: 3)\n",
    "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=1, stride=1), # conv1\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1, stride=1), # conv2\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), # 224 -> 112   # maxpool2\n",
    "            \n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1, stride=1),  # conv3\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1, stride=1),  # conv4\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), # 112 -> 56   # maxpool4\n",
    "            \n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1, stride=1),  #conv5\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1, stride=1),  # conv6\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1, stride=1),  # conv7\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), # 56 -> 28   # maxpool7\n",
    "\n",
    "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1, stride=1),  # conv8\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1, stride=1),  # conv9\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1, stride=1),  # conv10\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), # 28 -> 14   # maxpool10\n",
    "\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1, stride=1),  # conv11\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1, stride=1),  # conv12\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1, stride=1),  # conv13\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), # 14 -> 7   # maxpool13\n",
    "        )\n",
    "\n",
    "        self.fclayer = nn.Sequential(\n",
    "            nn.Linear(512 * 7 * 7, 4096),  # fc14\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(4096, 4096),  # fc15\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(4096, num_classes),  # fc16 = output\n",
    "            # nn.Softmax(dim=1), # Loss인 Cross Entropy Loss 에서 softmax를 포함한다.\n",
    "        )\n",
    "    \n",
    "    def forward(self, x:torch.Tensor):\n",
    "        x = self.convnet(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fclayer(x)\n",
    "        return x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
